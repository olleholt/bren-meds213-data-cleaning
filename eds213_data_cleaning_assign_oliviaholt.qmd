---
title: "Data Cleaning"
format: html
---

```{r}
#| message: false  

# Libraries
library(tidyverse)

# file names
datadir_raw <- "data/raw/"

datadir_processed <- "data/processed/"

species_file <- "ASDN_Daily_species.csv"

snowsurvey_file <- "ASDN_Snow_survey.csv"
```


## Snow survey data

### Data Exploration

Import the snow survey

```{r}
# Import the species
snowsurvey_csv <- read_csv(file.path(datadir_raw, snowsurvey_file))

glimpse(snowsurvey_csv)

```

Ok, the types are not what we were expecting for the percentages of cover. Let's find out why:

```{r}
snowsurvey_csv %>% 
  count(Water_cover)
```

Let's focus on the non-numeric values as a starting point:

```{r}
snowsurvey_csv %>% 
  count(Water_cover) %>%
  filter(is.na(as.numeric(Water_cover)))
```

### Data cleaning

Ok, we found our problematic values that are not numeric. There are a non-negligible number of cells with a dot as value. There is no mention of using this symbol in the metadata. We should probably have a look at those rows:

```{r}
snowsurvey_csv %>% 
  filter(Water_cover == ".") #%>% 
  #View()
```

Interestingly, when there is a "dot" for snow cover, it is also the case for all the other covers. Let's replace them all with NA since there is no supplemental information in the provided metadata

```{r}
snowsurvey_fixed <- snowsurvey_csv %>% 
  # filter(Snow_cover == ".") %>% 
  mutate(across(ends_with("_cover"), ~ifelse(.x == ".", NA, .x)))
```

We will now tackle the other problematic values:

The problem is similar with "-", let's set it to NA

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  # filter(Snow_cover == "-") %>%
  mutate(across(ends_with("_cover"), ~ifelse(.x == "-", NA, .x)))
```

"n/a" is pretty clear regarding how to fix it:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover == "n/a", NA, Water_cover))
```

"unk" is probably an abbreviation for unknown:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover == "unk", NA, Water_cover))
```

Finally we will set "<1" as zero (quite arbitrary indeed):

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover == "<1", "0", Water_cover))
```

Now we can test if we now only have NAs as non numeric values in the column:

```{r}
snowsurvey_fixed %>% 
  count(Water_cover) %>%
  filter(is.na(as.numeric(Water_cover)))
```

Ok, we can do the transformation:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = as.numeric(Water_cover))
```

Yeah we have finally a numeric column üéâ. Now we can verify that all the values are between 0 and 100:

```{r}
snowsurvey_fixed %>% 
  filter(Water_cover > 100) 
```

We have two values above 100, with an interesting 470%! ‚òÉÔ∏è We should probably set those values to NAs:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Water_cover = ifelse(Water_cover > 100, NA, Water_cover))
```

Let's check for negative values:

```{r}
snowsurvey_fixed %>% 
  filter(Water_cover < 0) 
```

No negative value detected ‚úÖ

Let's write the presence table to a csv file:

```{r}
write_csv(snowsurvey_fixed, file.path(datadir_processed, "water_cover.csv"))
```


# _____________________________________________________________________________________________________
# _____________________________________________________________________________________________________

## Part 2
## Land Cover

Clean the Land_cover column to transform it into the correct data type and respect expectations for a percentage

Ok, the types are not what we were expecting for the percentages of cover. Let's find out why:

```{r}
snowsurvey_csv %>% 
  count(Land_cover)
```

Let's focus on the non-numeric values as a starting point:

```{r}
snowsurvey_csv %>% 
  count(Land_cover) %>%
  filter(is.na(as.numeric(Land_cover)))
```

### Data cleaning

Ok, we found our problematic values that are not numeric. There are a non-negligible number of cells with a dot as value. There is no mention of using this symbol in the metadata. We should probably have a look at those rows:

```{r}
snowsurvey_csv %>% 
  filter(Land_cover == ".")# %>% 
  #View()
```

Interestingly, when there is a "dot" for snow cover, it is also the case for all the other covers. Let's replace them all with NA since there is no supplemental information in the provided metadata

```{r}
snowsurvey_fixed <- snowsurvey_csv %>% 
  # filter(Snow_cover == ".") %>% 
  mutate(across(ends_with("_cover"), ~ifelse(.x == ".", NA, .x)))
```

We will now tackle the other problematic values:

The problem is similar with "-", let's set it to NA

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  # filter(Snow_cover == "-") %>%
  mutate(across(ends_with("_cover"), ~ifelse(.x == "-", NA, .x)))
```

"n/a" is pretty clear regarding how to fix it:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover == "n/a", NA, Land_cover))
```

"unk" is probably an abbreviation for unknown:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover == "unk", NA, Land_cover))
```

Finally we will set "<1" as zero (quite arbitrary indeed):

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover == "<1", "0", Land_cover))
```

Now we can test if we now only have NAs as non numeric values in the column:

```{r}
snowsurvey_fixed %>% 
  count(Land_cover) %>%
  filter(is.na(as.numeric(Land_cover)))
```

Ok, we can do the transformation:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = as.numeric(Land_cover))
```

Yeah we have finally a numeric column üéâ. Now we can verify that all the values are between 0 and 100:

```{r}
snowsurvey_fixed %>% 
  filter(Land_cover > 100) 
```

We have two values above 100, with an interesting 470%! ‚òÉÔ∏è We should probably set those values to NAs:

```{r}
snowsurvey_fixed <- snowsurvey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover > 100, NA, Land_cover))
```

Let's check for negative values:

```{r}
snowsurvey_fixed %>% 
  filter(Land_cover < 0) 
```

Negative values were detected

```{r}

# Remove negative values and values over 100
snowsurvey_fixed <- snowsurvey_fixed %>%
  filter(Land_cover >= 0 & Land_cover <= 100)

# If you want to view the resulting dataframe
View(snowsurvey_fixed)

```


No negative value detected ‚úÖ

Let's write the presence table to a csv file:

```{r}
#write for new dataframe with cleaned land cover values
write_csv(snowsurvey_fixed, file.path(datadir_processed, "land_cover.csv"))
```

# _____________________________________________________________________________________________________
# _____________________________________________________________________________________________________

## Part 3
## Total_cover

Use the relationship between the three cover columns (Snow, Water, Land) to infer missing values where possible and recompute the Total_cover column

```{r}
# added three columns together
# still have lots that didn't equal 100 so we need to fix that
# we can use the relationship between the three cover columns to infer missing values where possible

# check the class of the columns
class(snowsurvey_fixed$Snow_cover)
class(snowsurvey_fixed$Water_cover)
class(snowsurvey_fixed$Land_cover)

#change snow and water to numeric
snowsurvey_fixed$Snow_cover <- as.numeric(snowsurvey_fixed$Snow_cover)
snowsurvey_fixed$Water_cover <- as.numeric(snowsurvey_fixed$Water_cover)

snowsurvey_fixed <- snowsurvey_fixed %>%
  mutate(Total_cover = Snow_cover + Water_cover + Land_cover) %>% 
  mutate(Total_cover = ifelse(Total_cover == 100, Total_cover, NA)) #%>% 

#now get rid of the NA's where Total_cover does not equal 100
snowsurvey_fixed <- snowsurvey_fixed %>%
  filter(!is.na(Total_cover))

# If you want to view the resulting dataframe
View(snowsurvey_fixed)


```

```{r}
#write for new dataframe with cleaned land cover values
write_csv(snowsurvey_fixed, file.path(datadir_processed, "total_cover.csv"))
```


